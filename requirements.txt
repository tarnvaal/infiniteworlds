# IMPORTANT: Install GPU components BEFORE this file
# 1) PyTorch (CUDA 12.4):
#    pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cu124 torch==2.6.0
# 2) llama.cpp with CUDA:
#    CMAKE_ARGS="-DGGML_CUDA=on" pip install --no-binary=:all: --no-cache-dir llama-cpp-python==0.3.16

# ---- Core API ----
fastapi==0.120.4
pydantic==2.12.3
uvicorn==0.38.0

# ---- Embeddings ----
sentence-transformers==5.1.2

# ---- (Optional) Testing ----
# pytest==8.4.2
# httpx==0.28.1
